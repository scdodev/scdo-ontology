#create_terms_for_review_file.py

#Programme that uses html files generated by Protege and a few user input files, to generate a file containing term annotations.

#Input required (edit "User Input" section at bottom of this file) in same location as program:
     # a file containing the list of terms to be reviewed (This can be done separately for each main class or all ontology terms can be given.) Easy way to create the file is to copy the tree of terms from Protege and paste in txt file (can right click on ontology name term and select "Copy sub-hierarchy as tab-indented text") --> see "input_file_complete_ontology_template" template as example
     # the location of the "index.html" file in the "classes" folder (created when running "Export OWLDoc" in Protege (in Tools menu)).
     # a list of properties, where the properties are the ones that you want to be displayed first and their order is the order they should be displayed in. 
     # the location of the "classes" folder (created when running "Export OWLDoc" in Protege (in Tools menu)).
     # the name of the outputfile to be created
     
#Debugging if encode errors arise:
     # comment out line 37 [f1 = open(input_file1, 'r', encoding="utf8")]
     # uncomment line 38 [f1 = open(input_file1, 'r', encoding="ISO-8859-1")]
     # uncomment line 65 [print(cleaned_term_name)] for a printout of offending term
     # run code with the above changes and hopefully the offending terms (containing bad formatting that should be fixed) will be printed out on the screen
     # fix the formatting of offending terms in the ontology file and re-generate html files in Protege
     # undo edits to the code in the first 3 steps above and rerun the code
     # redo this process if necessary
     
#25 January 2017
#Jade Hotchkiss

from bs4 import BeautifulSoup #first followed instructios here to install beautifulsoup: https://www.quora.com/What-is-the-step-by-step-procedure-to-install-Beautiful-Soup-In-Windows

terms_to_include = [] #list of terms to be added to the file for review
all_scdo_terms_dic = {} #dict of all terms in the ontology

custom_ordered_properties_list = [] # list of properties in the input file of custom ordered properties

properties_list = [] #list of properties
properties_total_occurrences_dic = {} # dictionary to keep track of how many terms have been annotated with certain properties. The properties (not including custom ordered properties) will be ordered in the output file according to how many terms they occur in.


##### Obtaining terms to be included in the file #####
def terms_to_include_list(input_file1):
     #f1 = open(input_file1, 'r', encoding="utf8") # opens the file and reads it with the "utf8" encoder
     f1 = open(input_file1, 'r', encoding="ISO-8859-1")  # opens the file and reads it with the "ISO-8859-1" encoder

     for row in f1: # loops through each row in the file
          row = (str(row.strip('\n')).strip()).strip("'") # strips the row of line endings and splits the row on tabs
          terms_to_include.append(row) # adds the term to the "terms_to_include" list
          
##### Creating dictionary of all terms in ontology (term name as key and term file iri as value) #####          
def entire_ontology_terms_to_html_file_dic(input_file2):
          
     file_parsed = BeautifulSoup(open(input_file2), "html.parser") # uses BeautifulSoup to read the index file (for html files produced by Protege)
    
     li_tags = file_parsed.find_all("li")  #obtains all the "li" tags

     for tag in li_tags:
          cleaned_term_name = [] # creates a list to which cleaned parts of the term name will be added
          a_tag = tag.contents[0] #"obtains the "a" tag within the "li" tag
               
          #####obtains the term name from the "a" tag
          term_name_list = a_tag.contents
          term_name = term_name_list[0]
          term_name = term_name.strip("'")
          
          term_name_split = term_name.split('\xa0') # splits the terms name on '\xa0'
          for word in term_name_split:
               word_cleaned = ''.join(i for i in word if ord(i)<128)
               cleaned_term_name.append(word_cleaned)
          cleaned_term_name = ' '.join(cleaned_term_name)
          
          iri_file_name = a_tag['href'] #obtains the content of the "href" attribute for the "a" tag
                                                                
          if term_name != 'owl:Thing': # excludes 'owl:Thing' class
               all_scdo_terms_dic[cleaned_term_name] = iri_file_name # adds the term name and iri_file_name to the "all_scdo_terms_dic" dictonary, as key and value respectively

##### Creating a list of custom ordered properties. This is so the user can specify which properties to have in the beginning of the output file and in which order #####
def create_ordered_NB_terms_list(input_file3):
     f3 = open(input_file3, 'r') # opens the file with annotation properties listed in order of preference
     for row in f3: # loops through each row
          property_name = row.strip('\n') 
          property_name_split = property_name.split('\xa0')
          cleaned_property_name = ' '.join(property_name_split)                
          if cleaned_property_name not in custom_ordered_properties_list:
               custom_ordered_properties_list.append(cleaned_property_name) # adds the property  name to the "custom_ordered_properties_list" list

##### This function is called in the next function #####
##### It creates an object of all div_tags that contain an "id" attribute but not a "class" attribute, thus not returning codebox div tags #####
def has_id_but_no_class(div_tag):
     return div_tag.has_attr('id') and not div_tag.has_attr('class')

               
##### Writes properties to the outputfile #####
def write_properties_to_output_file(classes_location, outputfile_name):
     from collections import defaultdict #used in "def write_properties_to_output_file()" to make the values in the dictionary a list by default.
     
     newf = open(outputfile_name + '.txt','w', encoding="utf8") # creates the new file to which term annotations will be written
     newf.write('parent class' + '\t' + 'ID' + '\t') # writes first 2 column headers

     for term in terms_to_include:   
          term_properties_list = []
          property_values_dic = {}
          property_values_dic = defaultdict(list) #Makes values in the dictionary in list form by default          
                              
          ##### Opens term's file with html parser #####
          filename = all_scdo_terms_dic[term] # retrieves the name of the html file for the term
          file_path = classes_location + "\\" + filename   # constructs the path of the file using the file name and location of the classes folder      
          f4 = BeautifulSoup(open(file_path, encoding = "ISO-8859-1"), "html.parser")  # opens the term's file using BeautifulSoup's html parser and "ISO-8859-1" encoding
          
          ### Creates an object of all tags containing annotation properties...i.e. a list of annotation properties used to annotate the term #####
          annotation_property_tags = f4.find_all("a", "Annotation Property") 
                   
          ##### Loops through annotation property tags in the file #####
          for a_tag in annotation_property_tags:
               cleaned_property_name = []
               
               ##### Obtains the property's name from the annotation tag #####             
               property_name = a_tag.contents[0] #"obtains the "a" tag within the "li" tag
               property_name = property_name.strip("'")
               
               property_name_split = property_name.split('\xa0')
               for word in property_name_split:
                    word_cleaned = ''.join(i for i in word if ord(i)<128)
                    cleaned_property_name.append(word_cleaned)
               cleaned_property_name = ' '.join(cleaned_property_name)                
               
               ##### Adds the property's name to the properties_list list (defined at the top of this file), if it is not already there #####
               if cleaned_property_name not in properties_list:     
                    properties_list.append(cleaned_property_name)               
               
                    ##### Adds the property's name to the term_properties_list list (defined at the top of the main loop run here), if it is not already there #####
                    if cleaned_property_name not in term_properties_list:
                         term_properties_list.append(cleaned_property_name)      
          
          ##### Loops through the list of annotation properties for the term (no duplicates of properties in the list) #####
          for item in term_properties_list:
               ##### If the property is not in the list of custom ordered properties, it is added to the properties_total_occurrences_dic, if it's not already there ##### 
               if item not in custom_ordered_properties_list:
                    if item not in properties_total_occurrences_dic:
                         properties_total_occurrences_dic[item] = 1
                    else:
                         properties_total_occurrences_dic[item] += 1         
                              
     ##### Concatenates the two different lists of properties (custom ordered and ordered by occurrence) for the header row #####
     header_row_properties_list = custom_ordered_properties_list + sorted(properties_total_occurrences_dic, key=properties_total_occurrences_dic.__getitem__, reverse=True)  
          
     ##### Writes properties to the output file's header row#header_row_properties_list ###
     for item in header_row_properties_list:
          newf.write(item + '\t')     
               
     ##### Ends the output file's header row #####
     newf.write('\n')     
     
     ##### List to keep track of the terms already written to output file #####
     terms_to_include_written = []
     
     ##### Loops through all term to include again and writes term details to the output file #####
     for term in terms_to_include:
          if term not in terms_to_include_written:
               terms_to_include_written.append(term) # add the term to the "terms_to_include_written" list, if not already included
               term_properties_list = [] # creates a list to which properties will be written for the term
               property_values_dic = {} # creates a dictionary to which annotations made by properties are assigned as values to the properties ( which are used as keys)
               property_values_dic = defaultdict(list) # Makes values in the dictionary in list form by default
               
               term_parent_classes_list = []
               
               filename = all_scdo_terms_dic[term]
               file_path = classes_location + "\\" + filename
               
               ##### Loops through all lines in the term's .txt file and adds annotation properties and their values to a dictionary #####
               file_parsed = BeautifulSoup(open(file_path, encoding="ISO-8859-1"), "html.parser") # opens the term's file using BeautifulSoup's html parser and "ISO-8859-1" encoding
               
               ##### Creates an object of the summary div tag #####
               summary_div_tag = file_parsed.find("div", 'summary')          
              
               ##### Creates an object of the li tags in the parsed file #####
               li_tags = file_parsed.find_all("li")
               
          
               for tag in li_tags:
                    if tag.a['class'] == ['Annotation', 'Property']:
                         cleaned_property_name = []      
                         p_name = tag.contents[0]
                         p_name = (p_name.string).strip("'")
                         
                         property_name_split = p_name.split('\xa0')
                         for word in property_name_split:
                              word_cleaned = ''.join(i for i in word if ord(i)<128)
                              cleaned_property_name.append(word_cleaned)
                         cleaned_property_name = ' '.join(cleaned_property_name)                        

                         if tag.contents[1] != ' ': # identifies if the second part of the li tag is empty and the tag is thus for a web link
                              web_link_part1 = tag.contents[1]
                              web_link_part2 = tag.contents[2]
                                                     
                              content = web_link_part1.string
                              content = content.strip()
                              
                              if web_link_part2.string != None:
                                   #if "<b>" in web_link_part2.string:
                                   web_link_part2_extracted = web_link_part2.contents
                                   content = content + web_link_part2_extracted[0].string
          
                         else:     
                              span_tag = tag.contents[2] #a span tag contains textual content, not a web link
                              content = (span_tag.text).strip('"')
                             
                         if content == None:
                              content = ""          
                    
                    
                    ##### Adds the property to the term_properties_list list if not already there #####
                    if cleaned_property_name not in term_properties_list:
                         term_properties_list.append(cleaned_property_name)                    
                              
                    ##### Adds the property's value/text to a list of values for the property #####
                    if cleaned_property_name not in property_values_dic:
                         property_values_dic[cleaned_property_name] = [content]
                    else:
                         property_values_dic[cleaned_property_name].append(content)     
                         
            
               ##### Creates an object of all div tags with id attribute, not class attribute, in the summary div tag #####
               ##### Calls the "has_id_but_no_class" function (see previous function) in order to do this #####
               id_div_tags = summary_div_tag.find_all(has_id_but_no_class)
                           
               ##### Loops through all div tags in the summary div tag that have an id attribute #####
               for div_tag in id_div_tags:
                    id_name = div_tag['id']
                    
                    ### Gets content of div_tag that specifies the term's superclasses (direct parent classes) and adds them to the term_parent_classes_list ###
                    if 'superclasses_' in id_name:
                         superclass_li_tags = div_tag.find_all("li")
                         
                         for superclass_li_tag in superclass_li_tags:
                              parent_classes_tags = superclass_li_tag.find_all("a")
                              
                              if len(parent_classes_tags) == 1:
                                   cleaned_parent_class_name = []                                 
                                   
                                   parent_class_name = parent_classes_tags[0].contents[0]
                                   parent_class_name_split = parent_class_name.split('\xa0')
                              
                                   for word in parent_class_name_split:
                                        word_cleaned = ''.join(i for i in word if ord(i)<128)
                                        cleaned_parent_class_name.append(word_cleaned)
                              
                                   cleaned_parent_class_name = ' '.join(cleaned_parent_class_name)   
                                   cleaned_parent_class_name = cleaned_parent_class_name.strip("'")
                                   term_parent_classes_list.append(cleaned_parent_class_name)                          
   
                                                              
               
               ##### Writes parent classes of the term to the first column in the output file #####
               if len(term_parent_classes_list) ==1:
                    newf.write(str(term_parent_classes_list[0]) + "\t")
               if len(term_parent_classes_list) >1:
                    newf.write(str((';').join(term_parent_classes_list)) + "\t")
                
               ##### If uncommented, this secton will write the first part of the term's filename to the second column, which can be used to obtain the term's SCDOID #####
               ID = ":".join(filename.split("_", 2)[:2])
               newf.write(ID + "\t")
               #newf.write(str(filename[:12]) + "\t")
               
               
               ##### Writes the term's name to the second column in the file #####
               newf.write(term + '\t')
                
                
               ##### Writes the content for each annotation porperty of the term to the output file #####              
               for item in header_row_properties_list[1:]:     
                    if item in term_properties_list:
                         if len(property_values_dic[item]) > 1:
                              newf.write(str((' | ').join(property_values_dic[item])) + "\t")
                         else:
                              newf.write(str(property_values_dic[item][0]) + "\t")
                              
                    else:
                         newf.write('\t')          
                         
               newf.write('\n')
     newf.close()          
     
def main():
     ##### User Input #####
     
     ## Input Files ##     
     input_file1 = "C:\\Users\\01440397\\Dropbox\\Work_2016\\Hearing Loss Ontology\\html view of HIO\\input_file_complete_SCDO_15April2021.txt" # file containing the list of terms to be extracted
     input_file2 = "C:\\Users\\01440397\\Dropbox\\Work_2016\\SCDO\\html view of SCDO\Most_recent_SCDO_html\\classes\index.html" #"C:\\Users\\01440397\Dropbox\Work_2016\SCDO\html view of SCDO\Most_recent_SCDO_html\classes\index.html" # location of the "index.html" file in the "classes" folder 
     input_file3 = "C:\\Users\\01440397\\Dropbox\\Work_2016\\SCDO\\html view of SCDO\\NB_properties_in_order.txt" # file of important annotation properties, in the order of preference 
      
     ## Other variables ##
     classes_location = "C:\\Users\\01440397\\Dropbox\Work_2016\\SCDO\\html view of SCDO\\Most_recent_SCDO_html\\classes" #"C:\\Users\\01440397\Dropbox\Work_2016\SCDO\html view of SCDO\Most_recent_SCDO_html\classes" # location of the "classes" folder (part of html content generated by Protege)
     outputfile_name = "C:\\Users\\01440397\\Dropbox\\Work_2016\\SCDO\\Submitting terms to other ontologies\\All_SCDO_terms_for_25Nov2021" #"C:\\Users\\01440397\Dropbox\Work_2016\SCDO\html view of SCDO\All_SCDO_terms_for_review_19March2021" # name of output file that will be generated
     
     ##### Functions #####
     terms_to_include_list(input_file1)
     entire_ontology_terms_to_html_file_dic(input_file2)
     create_ordered_NB_terms_list(input_file3)
     write_properties_to_output_file(classes_location, outputfile_name)
    
if __name__ == '__main__':               
          main()